# AirSim Data Processing Toolkit

[![GitHub Repository](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/chungita/AIRSIM_DeepLearning_Binocular_DepthData_Generator)
[![Platform](https://img.shields.io/badge/Platform-Windows%2010%2F11-blue)](https://github.com/chungita/AIRSIM_DeepLearning_Binocular_DepthData_Generator)
[![Python](https://img.shields.io/badge/Python-3.7%2B-blue)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-Research-green)](https://github.com/chungita/AIRSIM_DeepLearning_Binocular_DepthData_Generator)

A comprehensive Python-based toolkit for processing, annotating, and analyzing AirSim simulation data. This toolkit provides a complete workflow from raw data processing to labeled dataset generation for computer vision and autonomous driving research.

> **Platform**: Currently designed for Windows 10/11 operating systems.  
> **Repository**: [https://github.com/chungita/AIRSIM_DeepLearning_Binocular_DepthData_Generator](https://github.com/chungita/AIRSIM_DeepLearning_Binocular_DepthData_Generator)

## ğŸ¯ Features

- **Multi-language Support**: Full support for Chinese and English interfaces
- **Data Generation**: Process raw AirSim data into depth maps, disparity maps, and organized image sequences
- **Image Annotation**: Manual and automatic annotation tools with YOLO and MOT format support
- **Visualization Tools**: Comprehensive viewers for images, labels, and tracking results
- **3D Tracking**: Object trajectory analysis with 3D coordinate support
- **Export Options**: Generate GIFs and videos from image sequences

## ğŸš€ Getting Started

### Prerequisites

#### Required Software
- **Windows 10 or 11** (Currently Windows only)
- **Unreal Engine 4 (UE4)** - Download from [Epic Games Launcher](https://www.unrealengine.com/)
- **AirSim** - Download and setup from [AirSim GitHub](https://github.com/microsoft/AirSim)

#### Python Dependencies
- Python 3.7+
- PyQt5
- NumPy
- OpenCV
- Other dependencies listed in `requirements.txt`

> **Important**: Make sure you have UE4 and AirSim properly installed and configured before using this toolkit to process simulation data.

### Installation

#### Step 1: Install UE4 and AirSim

1. Download and install **Unreal Engine 4** from [Epic Games Launcher](https://www.unrealengine.com/)
2. Download and setup **AirSim** following the [official documentation](https://github.com/microsoft/AirSim)
3. Configure AirSim in your UE4 environment

#### Step 2: Install Data Processing Toolkit

1. Clone or download this repository:
```bash
git clone https://github.com/chungita/AIRSIM_DeepLearning_Binocular_DepthData_Generator.git
cd AIRSIM_DeepLearning_Binocular_DepthData_Generator
```

2. Install required dependencies:
```bash
pip install -r requirements.txt
```

3. Launch the control panel:
```bash
python Control_Panel.py
```

### Initial Setup

Before processing data:

1. **Configure AirSim**: Use the sample configuration from `Airsim settings/settings.json` as a reference for your AirSim setup
2. **Collect Data**: Run your AirSim simulation to collect raw data
3. **Prepare Data**: Copy your AirSim simulation data to the `RawData/` folder
4. **Configure Processing**: Adjust parameters in `Tools&Settings/Settings.txt` according to your camera setup

## ğŸ“‹ Tools Overview

### 1. Data Generator (`DataGenerator.py`)
- Process raw AirSim data
- Generate depth maps (DepthGT_*.pfm)
- Generate disparity maps (Disparity_*.pfm)
- Organize left/right camera images (Img0_*, Img1_*)
- Process semantic segmentation images (Seg_*)
- Copy results to output folder

### 2. Image Labeler (`Img_Labeler.py`)
- **Manual Mode**: Draw bounding boxes manually
- **Batch Mode**: Automatic color-based object detection
- Generate YOLO format labels
- Generate MOT format labels with 3D coordinates
- Save annotation statistics and results

### 3. Image Viewer (`PIC_Read.py`)
- View depth maps with customizable color mapping
- View disparity maps
- View original camera images
- Support for various image formats

### 4. Label Viewer (`Label_Show.py`)
- Visualize YOLO format annotations
- Visualize MOT format annotations
- Verify bounding box accuracy
- Class distribution analysis

### 5. Track Analyzer (`Track.py`)
- Display object trajectories
- 3D position tracking
- Multi-object tracking visualization
- Export tracking results

### 6. GIF Generator (`Gifer.py`)
- Create animated GIFs from image sequences
- Customizable frame rate and quality
- Batch processing support

### 7. Video Converter (`Video_Convertor.py`)
- Convert image sequences to video files
- Multiple video format support
- Configurable encoding settings

## ğŸ“ Project Structure

```
DataGenerator/
â”œâ”€â”€ Control_Panel.py          # Main control panel application
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ RawData/                  # Raw AirSim data input folder
â”œâ”€â”€ ProcessData/              # Processed images and depth data
â”œâ”€â”€ Results/                  # Final output folder
â”‚   â”œâ”€â”€ Img/                 # Final image output
â”‚   â”œâ”€â”€ YOLO_Label/          # YOLO format label files
â”‚   â””â”€â”€ MOT_Label/           # MOT format label files
â”œâ”€â”€ Airsim settings/
â”‚   â””â”€â”€ settings.json        # AirSim configuration (sample settings available)
â””â”€â”€ Tools&Settings/
    â”œâ”€â”€ DataGenerator.py     # Data processing tool
    â”œâ”€â”€ Img_Labeler.py       # Image annotation tool
    â”œâ”€â”€ PIC_Read.py          # Image viewer
    â”œâ”€â”€ Label_Show.py        # Label viewer
    â”œâ”€â”€ Track.py             # Tracking analyzer
    â”œâ”€â”€ Gifer.py             # GIF generator
    â”œâ”€â”€ Video_Convertor.py   # Video converter
    â”œâ”€â”€ Settings.txt         # Main configuration file
    â”œâ”€â”€ Settings_Editor.py   # Settings editor GUI
    â””â”€â”€ predefined_classes.txt # Object class definitions
```

## ğŸ”§ Workflow

### Recommended Processing Order:

1. **Prepare Raw Data**: Place AirSim data in the `RawData/` folder. You can also use the sample configuration from the `Airsim settings/` folder
2. **Check Settings**: Verify parameters in `Settings.txt` (camera parameters, paths, etc.)
3. **Run Data Generator**: Process raw data and generate depth/disparity maps
4. **Annotate Images**: Use manual or automatic mode to label objects
5. **Verify Results**: Use viewers to confirm annotation quality
6. **Generate Output**: Export labels and create demo animations

## âš™ï¸ Configuration

### AirSim Configuration

The `Airsim settings/settings.json` file contains sample AirSim configuration:
- Camera sensor settings
- Stereo camera setup
- Image capture settings
- Use this as a reference when configuring your AirSim environment

### Processing Configuration

The main configuration file `Tools&Settings/Settings.txt` contains:
- Camera parameters (focal length, baseline, image dimensions)
- Input/output paths
- Processing settings
- Color thresholds for automatic annotation

Edit settings using:
- Built-in Settings Editor (accessible from Control Panel)
- Manual editing of `Settings.txt`

## ğŸ’¡ Tips & Best Practices

- **Depth Map Issues**: Check MaxDepth setting if depth maps display abnormally
- **Poor Annotation**: Adjust color threshold parameters in settings
- **Batch Processing**: Test with a small range before processing large datasets
- **Backup**: Regularly backup important annotation results
- **Performance**: Close unused viewer windows to improve performance

## ğŸ–¥ï¸ System Requirements

- **OS**: Windows 10/11 (Currently Windows only)
- **RAM**: 8GB minimum, 16GB recommended
- **Storage**: Depends on dataset size (allow several GB for processed data)
- **Display**: 1920x1080 minimum resolution recommended

> **Note**: This toolkit is currently optimized for Windows operating systems. Linux and macOS support may be added in future releases.

## ğŸŒ Language Support

The toolkit supports both Chinese and English interfaces. Click the "ğŸŒ Language" button in the Control Panel to switch between languages. All tools will launch with the selected language.

## ğŸ“ Output Formats

### YOLO Format
```
<class_id> <x_center> <y_center> <width> <height>
```
All values are normalized (0.0 to 1.0)

### MOT Format
```
<frame_id>,<track_id>,<x>,<y>,<width>,<height>,<confidence>,<class_id>,<visibility>,<x_3d>,<y_3d>,<z_3d>
```
Includes 3D coordinates from depth information

## ğŸ› Troubleshooting

- **Import Errors**: Ensure all dependencies are installed via `pip install -r requirements.txt`
- **File Not Found**: Check that paths in `Settings.txt` are correct
- **GUI Not Displaying**: Verify PyQt5 installation: `pip install PyQt5`
- **Depth Map Errors**: Ensure .pfm files are valid and not corrupted
- **No Data to Process**: Verify that AirSim simulation has been run and data has been collected
- **AirSim Configuration Issues**: Refer to the [AirSim documentation](https://microsoft.github.io/AirSim/) for setup help

## ğŸ“„ License

This project is provided as-is for research and educational purposes.

## ğŸ¤ Contributing

Contributions, issues, and feature requests are welcome! Feel free to check the [issues page](https://github.com/chungita/AIRSIM_DeepLearning_Binocular_DepthData_Generator/issues).

If you find this project helpful, please consider giving it a â­ on [GitHub](https://github.com/chungita/AIRSIM_DeepLearning_Binocular_DepthData_Generator)!

## ğŸ‘¥ Authors

- **chungita** - [GitHub Profile](https://github.com/chungita)
- Dataset Generation and Processing Tools
- AirSim Integration

## ğŸ“§ Contact

For questions or support, please open an issue in the [repository](https://github.com/chungita/AIRSIM_DeepLearning_Binocular_DepthData_Generator/issues).

---

## ğŸ“Œ Important Notes

- **AirSim Dependency**: This toolkit is specifically designed to process data collected from AirSim simulations running in Unreal Engine 4
- **Pre-requisites**: You must have UE4 and AirSim installed and configured before using this data processing toolkit
- **Data Source**: The toolkit processes simulation data from AirSim, not real-world data
- **Configuration**: Use the sample settings in `Airsim settings/settings.json` as a reference when setting up your AirSim environment

For more information about AirSim setup and usage, visit the [official AirSim documentation](https://microsoft.github.io/AirSim/).

## ğŸ”— Related Links

- **GitHub Repository**: [AIRSIM_DeepLearning_Binocular_DepthData_Generator](https://github.com/chungita/AIRSIM_DeepLearning_Binocular_DepthData_Generator)
- **AirSim Official**: [Microsoft AirSim](https://github.com/microsoft/AirSim)
- **Unreal Engine**: [Epic Games Unreal Engine](https://www.unrealengine.com/)
- **AirSim Documentation**: [https://microsoft.github.io/AirSim/](https://microsoft.github.io/AirSim/)

---

Made with â¤ï¸ for computer vision and autonomous driving research

